from __future__ import annotations
"""ì›ê³  ë¶„ì„ ëª¨ë“ˆ â€” í†µê³„, ëª©ì°¨, ì°¸ê³ ë¬¸í—Œ, ìƒ‰ì¸ ê¸°ëŠ¥"""

import re
import math
import json
from collections import Counter
from dataclasses import dataclass, field
from typing import Optional


# â”€â”€ íŒí˜•ë³„ í•œ í˜ì´ì§€ ê¸€ììˆ˜ (ëŒ€ëµì  ê¸°ì¤€) â”€â”€
PAGE_CHAR_MAP = {
    "A5": 800,       # ì¼ë°˜ ë‹¨í–‰ë³¸
    "ì‹ êµ­íŒ": 900,    # í•™ìˆ ì„œ
    "46íŒ": 700,      # ì†Œì„¤/ì—ì„¸ì´
    "B5": 1100,       # êµì¬
    "A4": 1500,       # ë³´ê³ ì„œ
}

# í‰ê·  ì½ê¸° ì†ë„ (í•œêµ­ì–´ ê¸€ì/ë¶„)
READING_SPEED_KO = 500


@dataclass
class ManuscriptStats:
    """ì›ê³  í†µê³„ ê²°ê³¼"""
    total_chars: int = 0
    chars_no_space: int = 0
    word_count: int = 0
    sentence_count: int = 0
    paragraph_count: int = 0
    page_estimates: dict = field(default_factory=dict)
    reading_time_minutes: float = 0.0

    def to_dict(self) -> dict:
        return {
            "ì´ ê¸€ììˆ˜": f"{self.total_chars:,}",
            "ê³µë°± ì œì™¸ ê¸€ììˆ˜": f"{self.chars_no_space:,}",
            "ë‹¨ì–´ìˆ˜": f"{self.word_count:,}",
            "ë¬¸ì¥ìˆ˜": f"{self.sentence_count:,}",
            "ë¬¸ë‹¨ìˆ˜": f"{self.paragraph_count:,}",
            "ì˜ˆìƒ í˜ì´ì§€ìˆ˜": self.page_estimates,
            "ì˜ˆìƒ ì½ê¸° ì‹œê°„": f"{self.reading_time_minutes:.1f}ë¶„ (ì•½ {math.ceil(self.reading_time_minutes / 60)}ì‹œê°„)",
        }


@dataclass
class TOCEntry:
    """ëª©ì°¨ í•­ëª©"""
    level: int
    title: str
    line_number: int

    def to_dict(self) -> dict:
        return {"level": self.level, "title": self.title, "line": self.line_number}


@dataclass
class Reference:
    """ì°¸ê³ ë¬¸í—Œ í•­ëª©"""
    ref_id: str
    authors: list[str]
    title: str
    year: int
    publisher: str = ""
    journal: str = ""
    volume: str = ""
    pages: str = ""
    url: str = ""

    def format_apa(self) -> str:
        authors_str = ", ".join(self.authors)
        base = f"{authors_str} ({self.year}). {self.title}."
        if self.journal:
            base += f" *{self.journal}*"
            if self.volume:
                base += f", *{self.volume}*"
            if self.pages:
                base += f", {self.pages}"
            base += "."
        elif self.publisher:
            base += f" {self.publisher}."
        if self.url:
            base += f" {self.url}"
        return base

    def format_chicago(self) -> str:
        authors_str = ", ".join(self.authors)
        base = f"{authors_str}. *{self.title}*."
        if self.publisher:
            base += f" {self.publisher},"
        base += f" {self.year}."
        if self.url:
            base += f" {self.url}."
        return base

    def format_mla(self) -> str:
        authors_str = ", ".join(self.authors)
        base = f"{authors_str}. \"{self.title}.\""
        if self.journal:
            base += f" *{self.journal}*"
            if self.volume:
                base += f", vol. {self.volume}"
            if self.pages:
                base += f", pp. {self.pages}"
            base += f", {self.year}."
        elif self.publisher:
            base += f" {self.publisher}, {self.year}."
        if self.url:
            base += f" {self.url}."
        return base

    def format(self, style: str = "apa") -> str:
        formatters = {
            "apa": self.format_apa,
            "chicago": self.format_chicago,
            "mla": self.format_mla,
        }
        formatter = formatters.get(style.lower(), self.format_apa)
        return formatter()


class ManuscriptAnalyzer:
    """ì›ê³  ë¶„ì„ê¸°"""

    # ì±•í„°/ì„¹ì…˜ ê°ì§€ íŒ¨í„´
    HEADING_PATTERNS = [
        (1, re.compile(r"^#\s+(.+)$", re.MULTILINE)),
        (2, re.compile(r"^##\s+(.+)$", re.MULTILINE)),
        (3, re.compile(r"^###\s+(.+)$", re.MULTILINE)),
        (4, re.compile(r"^####\s+(.+)$", re.MULTILINE)),
        (1, re.compile(r"^ì œ?\s*(\d+)\s*[ì¥í¸ë¶€]\s*[.:Â·\-â€”\s]*(.+)$", re.MULTILINE)),
        (2, re.compile(r"^ì œ?\s*(\d+)\s*[ì ˆê³¼]\s*[.:Â·\-â€”\s]*(.+)$", re.MULTILINE)),
        (1, re.compile(r"^(Chapter|CHAPTER)\s+\d+\s*[.:Â·\-â€”\s]*(.*)$", re.MULTILINE)),
        (2, re.compile(r"^(Section|SECTION)\s+\d+\s*[.:Â·\-â€”\s]*(.*)$", re.MULTILINE)),
    ]

    # í•œêµ­ì–´ ë¶ˆìš©ì–´
    STOPWORDS_KO = {
        "ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë°", "ë˜", "ë˜í•œ", "ì˜", "ë¥¼", "ì„",
        "ì—", "ì—ì„œ", "ì™€", "ê³¼", "ë¡œ", "ìœ¼ë¡œ", "ì€", "ëŠ”", "ê°€", "ì´ë‹¤", "í•˜ë‹¤",
        "ë˜ë‹¤", "ìˆë‹¤", "ì—†ë‹¤", "ì•Šë‹¤", "í•œ", "í• ", "í•˜ëŠ”", "ëœ", "ë˜ëŠ”", "í•˜ê³ ",
        "ê·¸ë¦¬ê³ ", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ë•Œë¬¸", "ìœ„í•´", "ëŒ€í•œ", "í†µí•´", "ë”°ë¼",
    }

    def __init__(self):
        self._references: dict[str, Reference] = {}

    # â”€â”€ í†µê³„ ë¶„ì„ â”€â”€

    def analyze_stats(self, text: str) -> ManuscriptStats:
        """ì›ê³  í†µê³„ ë¶„ì„"""
        stats = ManuscriptStats()
        stats.total_chars = len(text)
        stats.chars_no_space = len(text.replace(" ", "").replace("\t", "").replace("\n", ""))
        stats.word_count = len(text.split())
        stats.sentence_count = len(re.findall(r"[.!?ã€‚ï¼ï¼Ÿ]+", text))
        if stats.sentence_count == 0 and text.strip():
            stats.sentence_count = 1
        paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
        stats.paragraph_count = len(paragraphs) if paragraphs else (1 if text.strip() else 0)
        stats.page_estimates = {
            fmt: math.ceil(stats.chars_no_space / chars_per_page)
            for fmt, chars_per_page in PAGE_CHAR_MAP.items()
        }
        stats.reading_time_minutes = round(stats.chars_no_space / READING_SPEED_KO, 1)
        return stats

    # â”€â”€ ëª©ì°¨ ìƒì„± â”€â”€

    def generate_toc(self, text: str) -> list[TOCEntry]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì±•í„°/ì„¹ì…˜ ì œëª©ì„ ì¶”ì¶œí•˜ì—¬ ëª©ì°¨ ìƒì„±"""
        entries: list[tuple[int, int, str]] = []  # (line_num, level, title)
        lines = text.split("\n")

        for line_idx, line in enumerate(lines, 1):
            stripped = line.strip()
            if not stripped:
                continue
            for level, pattern in self.HEADING_PATTERNS:
                m = pattern.match(stripped)
                if m:
                    # ë§ˆí¬ë‹¤ìš´ í—¤ë”©: ê·¸ë£¹ 1ì´ ì œëª©
                    # í•œêµ­ì–´ íŒ¨í„´: ë§ˆì§€ë§‰ ê·¸ë£¹ì´ ì œëª©
                    title = m.group(m.lastindex) if m.lastindex else m.group(1)
                    title = title.strip()
                    if title:
                        entries.append((line_idx, level, title))
                    break

        # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¤„ì—ì„œ ì—¬ëŸ¬ íŒ¨í„´ ë§¤ì¹­ ë°©ì§€)
        seen_lines: set[int] = set()
        unique: list[TOCEntry] = []
        for line_num, level, title in entries:
            if line_num not in seen_lines:
                seen_lines.add(line_num)
                unique.append(TOCEntry(level=level, title=title, line_number=line_num))

        return unique

    def format_toc(self, entries: list[TOCEntry]) -> str:
        """ëª©ì°¨ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not entries:
            return "ëª©ì°¨ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì±•í„°/ì„¹ì…˜ ì œëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)"
        lines = ["ğŸ“– **ëª©ì°¨**", ""]
        for entry in entries:
            indent = "  " * (entry.level - 1)
            lines.append(f"{indent}â€¢ {entry.title}")
        return "\n".join(lines)

    # â”€â”€ ì°¸ê³ ë¬¸í—Œ ê´€ë¦¬ â”€â”€

    def add_reference(self, ref: Reference) -> None:
        """ì°¸ê³ ë¬¸í—Œ ì¶”ê°€"""
        self._references[ref.ref_id] = ref

    def get_reference(self, ref_id: str) -> Optional[Reference]:
        """ì°¸ê³ ë¬¸í—Œ ì¡°íšŒ"""
        return self._references.get(ref_id)

    def list_references(self, style: str = "apa") -> list[str]:
        """ëª¨ë“  ì°¸ê³ ë¬¸í—Œì„ ì§€ì • ìŠ¤íƒ€ì¼ë¡œ í¬ë§·íŒ…í•˜ì—¬ ë°˜í™˜"""
        refs = sorted(self._references.values(), key=lambda r: (r.authors[0] if r.authors else "", r.year))
        return [ref.format(style) for ref in refs]

    def load_references(self, data: list[dict]) -> int:
        """JSON ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì°¸ê³ ë¬¸í—Œ ì¼ê´„ ë¡œë“œ"""
        count = 0
        for item in data:
            ref = Reference(
                ref_id=item.get("id", item.get("ref_id", f"ref_{count}")),
                authors=item.get("authors", []),
                title=item.get("title", ""),
                year=item.get("year", 0),
                publisher=item.get("publisher", ""),
                journal=item.get("journal", ""),
                volume=item.get("volume", ""),
                pages=item.get("pages", ""),
                url=item.get("url", ""),
            )
            self.add_reference(ref)
            count += 1
        return count

    # â”€â”€ ìƒ‰ì¸ ìƒì„± â”€â”€

    def generate_index(
        self, text: str, min_freq: int = 3, max_items: int = 50
    ) -> list[tuple[str, int]]:
        """ì£¼ìš” í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ìœ¼ë¡œ ìƒ‰ì¸ í•­ëª© ìƒì„±"""
        # í•œêµ­ì–´ + ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ
        words = re.findall(r"[ê°€-í£]{2,}|[a-zA-Z]{3,}", text)
        words_lower = [w.lower() for w in words]

        # ë¶ˆìš©ì–´ ì œê±°
        filtered = [w for w in words_lower if w not in self.STOPWORDS_KO and len(w) >= 2]

        counter = Counter(filtered)
        # ë¹ˆë„ ê¸°ì¤€ í•„í„°ë§
        index_items = [
            (word, freq)
            for word, freq in counter.most_common(max_items * 2)
            if freq >= min_freq
        ][:max_items]

        # ê°€ë‚˜ë‹¤/ì•ŒíŒŒë²³ ìˆœ ì •ë ¬
        index_items.sort(key=lambda x: x[0])
        return index_items

    def format_index(self, index_items: list[tuple[str, int]]) -> str:
        """ìƒ‰ì¸ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not index_items:
            return "ìƒ‰ì¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¶©ë¶„í•œ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)"
        lines = ["ğŸ“‘ **ìƒ‰ì¸**", ""]
        current_initial = ""
        for word, freq in index_items:
            initial = word[0].upper()
            if initial != current_initial:
                current_initial = initial
                lines.append(f"\n**[{current_initial}]**")
            lines.append(f"  {word} ({freq})")
        return "\n".join(lines)
